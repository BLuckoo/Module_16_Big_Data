{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNRKDQ1b2HPPpy9w6wA6OwA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BLuckoo/Module_16_Big_Data/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb8PVICeVw5o",
        "outputId": "f21ac6a4-7864-480c-cd8d-e1231e10cf86"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.0.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 43.1 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 69.2 kB/88.7\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 69.2 kB/88.7 kB 78%] [Waiting for headers\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [1 InRelease 72.1 kB/88.7 k\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 2,572 B/15.9 k\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 5,468 B/15.9 k\r                                                                               \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 11.3 kB/15.9 k\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/15.9 k\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/15.9 k\r                                                                               \rGet:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [62.9 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [510 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,263 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,420 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB]\n",
            "Ign:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [695 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,786 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,195 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [914 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [39.5 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,698 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [544 kB]\n",
            "Get:28 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.1 kB]\n",
            "Fetched 13.5 MB in 5s (2,813 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZlI5e26WtYy"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Demographics\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c64TpMbGW-cR",
        "outputId": "62626144-93f6-4e5b-94e3-2118e2e4bdef"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://s3.amazonaws.com/dataviz-curriculum/day_1/demographics.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"demographics.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n",
            "| id|                name|age|height_meter|weight_kg|children|        occupation|academic_degree|salary|     location|\n",
            "+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n",
            "|  0|       Darlena Avila| 58|        1.87|       53|       1|     Choreographer|            PhD|    68| South Dakota|\n",
            "|  1|            Yan Boyd| 65|         1.8|       40|       0|         Cellarman|       Bachelor|    73|     Delaware|\n",
            "|  2|         Joette Lane| 32|         1.8|       73|       1|Veterinary Surgeon|         Master|    69| South Dakota|\n",
            "|  3|        Jazmine Hunt| 61|        1.79|       89|       0|            Hawker|            PhD|    88|    Louisiana|\n",
            "|  4|      Remedios Gomez| 23|        1.64|       51|       2|     Choreographer|       Bachelor|    83|West Virginia|\n",
            "|  5|        Myung Brewer| 20|        1.68|       60|       4|    Window Dresser|       Bachelor|    65| South Dakota|\n",
            "|  6|         Shaun Lynch| 31|        1.56|       62|       0|            Weaver|         Master|    72|    Louisiana|\n",
            "|  7|     Melodi Mcdowell| 56|         1.6|       42|       0| Lighthouse Keeper|         Master|    65|    Louisiana|\n",
            "|  8|Charlesetta Steve...| 30|        1.62|       44|       3|        Millwright|         Master|    87|    Louisiana|\n",
            "|  9|       Merri Charles| 44|        1.69|       51|       5|  Medical Supplier|            PhD|    72|West Virginia|\n",
            "| 10|        Cassi Meyers| 55|        1.82|       72|       5|        Manicurist|       Bachelor|    73| South Dakota|\n",
            "| 11|      Shawnee Harmon| 66|        1.63|       78|       5| Medical Physicist|            PhD|    90|     Delaware|\n",
            "| 12|       Lyndia Spears| 62|        1.88|       41|       1|         Assistant|         Master|    78|       Alaska|\n",
            "| 13|          Page Evans| 35|        1.53|       74|       5|         Paramedic|       Bachelor|    69|     Delaware|\n",
            "| 14|        Telma Hebert| 66|        1.94|       79|       3|       Genealogist|         Master|    75| South Dakota|\n",
            "| 15|      Edelmira Drake| 23|        1.87|       72|       2|           Servant|            PhD|    77| South Dakota|\n",
            "| 16|       Oscar Guthrie| 40|        1.61|       46|       4| Technical Liaison|       Bachelor|    76|    Louisiana|\n",
            "| 17|   Bernardina Strong| 34|        1.55|       78|       1|         Scientist|            PhD|    90| South Dakota|\n",
            "| 18|        Caprice Hart| 64|        1.69|       67|       4|   Market Research|            PhD|    79|    Louisiana|\n",
            "| 19|         Alleen Pace| 25|        1.86|       81|       4|  Medical Supplier|            PhD|    77| South Dakota|\n",
            "+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRjKgjzNaFtg",
        "outputId": "25256f68-7b1c-4efe-ed91-c46ed1d64d43"
      },
      "source": [
        "# Print the column names\n",
        "df.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id',\n",
              " 'name',\n",
              " 'age',\n",
              " 'height_meter',\n",
              " 'weight_kg',\n",
              " 'children',\n",
              " 'occupation',\n",
              " 'academic_degree',\n",
              " 'salary',\n",
              " 'location']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsXkJetAaZV9",
        "outputId": "574a0f5a-797a-4610-b4af-367d3eb4c041"
      },
      "source": [
        "# Print out the first 10 rows\n",
        "df.show(10)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n",
            "| id|                name|age|height_meter|weight_kg|children|        occupation|academic_degree|salary|     location|\n",
            "+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n",
            "|  0|       Darlena Avila| 58|        1.87|       53|       1|     Choreographer|            PhD|    68| South Dakota|\n",
            "|  1|            Yan Boyd| 65|         1.8|       40|       0|         Cellarman|       Bachelor|    73|     Delaware|\n",
            "|  2|         Joette Lane| 32|         1.8|       73|       1|Veterinary Surgeon|         Master|    69| South Dakota|\n",
            "|  3|        Jazmine Hunt| 61|        1.79|       89|       0|            Hawker|            PhD|    88|    Louisiana|\n",
            "|  4|      Remedios Gomez| 23|        1.64|       51|       2|     Choreographer|       Bachelor|    83|West Virginia|\n",
            "|  5|        Myung Brewer| 20|        1.68|       60|       4|    Window Dresser|       Bachelor|    65| South Dakota|\n",
            "|  6|         Shaun Lynch| 31|        1.56|       62|       0|            Weaver|         Master|    72|    Louisiana|\n",
            "|  7|     Melodi Mcdowell| 56|         1.6|       42|       0| Lighthouse Keeper|         Master|    65|    Louisiana|\n",
            "|  8|Charlesetta Steve...| 30|        1.62|       44|       3|        Millwright|         Master|    87|    Louisiana|\n",
            "|  9|       Merri Charles| 44|        1.69|       51|       5|  Medical Supplier|            PhD|    72|West Virginia|\n",
            "+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aclR-Nn8c-tC",
        "outputId": "a8671dd6-99e8-4d36-ecce-765ad27a3609"
      },
      "source": [
        "# Select the age, height_meter, and weight_kg columns and use describe to show the summary statistics\n",
        "df.select([\"age\", \"height_meter\", \"weight_kg\"]).describe().show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+------------------+------------------+\n",
            "|summary|               age|      height_meter|         weight_kg|\n",
            "+-------+------------------+------------------+------------------+\n",
            "|  count|              1000|              1000|              1000|\n",
            "|   mean|            42.933|1.7519499999999995|            64.011|\n",
            "| stddev|14.255445581556843|0.1436897499623555|15.005733939099779|\n",
            "|    min|                18|               1.5|                38|\n",
            "|    max|                67|                 2|                90|\n",
            "+-------+------------------+------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZWDx_4UdKRj",
        "outputId": "7946b298-d746-4507-f645-7be84caa5eea"
      },
      "source": [
        "# Print the schema to see the types\n",
        "df.printSchema()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- height_meter: string (nullable = true)\n",
            " |-- weight_kg: string (nullable = true)\n",
            " |-- children: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- academic_degree: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shOPBdosdRYv",
        "outputId": "45d50977-a348-4b82-c575-194a0c372fb7"
      },
      "source": [
        "# Rename the Salary column to `Salary (1k)` and show only this new column\n",
        "df = df.withColumnRenamed('Salary', 'Salary (1k)')\n",
        "df.select(\"Salary (1k)\").show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|Salary (1k)|\n",
            "+-----------+\n",
            "|         68|\n",
            "|         73|\n",
            "|         69|\n",
            "|         88|\n",
            "|         83|\n",
            "|         65|\n",
            "|         72|\n",
            "|         65|\n",
            "|         87|\n",
            "|         72|\n",
            "|         73|\n",
            "|         90|\n",
            "|         78|\n",
            "|         69|\n",
            "|         75|\n",
            "|         77|\n",
            "|         76|\n",
            "|         90|\n",
            "|         79|\n",
            "|         77|\n",
            "+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6y5unwIdYiP",
        "outputId": "6e256929-7f53-406f-ad89-905e1a1a6c58"
      },
      "source": [
        "# Create a new column called `Salary` where the values are the `Salary (1k)` * 1000\n",
        "# Show the columns `Salary` and `Salary (1k)`\n",
        "df = df.withColumn(\"Salary\", df[\"Salary (1k)\"] * 1000)\n",
        "df.select([\"Salary\", \"Salary (1k)\"]).show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+\n",
            "| Salary|Salary (1k)|\n",
            "+-------+-----------+\n",
            "|68000.0|         68|\n",
            "|73000.0|         73|\n",
            "|69000.0|         69|\n",
            "|88000.0|         88|\n",
            "|83000.0|         83|\n",
            "|65000.0|         65|\n",
            "|72000.0|         72|\n",
            "|65000.0|         65|\n",
            "|87000.0|         87|\n",
            "|72000.0|         72|\n",
            "|73000.0|         73|\n",
            "|90000.0|         90|\n",
            "|78000.0|         78|\n",
            "|69000.0|         69|\n",
            "|75000.0|         75|\n",
            "|77000.0|         77|\n",
            "|76000.0|         76|\n",
            "|90000.0|         90|\n",
            "|79000.0|         79|\n",
            "|77000.0|         77|\n",
            "+-------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px3eRAP8g8p0",
        "outputId": "7f2b4d63-1d95-4df0-af67-a2c57d8a4bc6"
      },
      "source": [
        "#Occupation with highest salary\n",
        "\n",
        "df.orderBy(df[\"Salary\"].desc()).select(\"occupation\", \"Salary\").limit(1).show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------+\n",
            "|       occupation| Salary|\n",
            "+-----------------+-------+\n",
            "|Medical Physicist|90000.0|\n",
            "+-----------------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brf3NR93FlUc",
        "outputId": "7f872064-ac0d-4b27-b972-65dbeb9a9d61"
      },
      "source": [
        "# Occupation with lowest salary\n",
        "df.orderBy(df[\"Salary\"]).select(\"occupation\", \"Salary\").limit(1).show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-------+\n",
            "|    occupation| Salary|\n",
            "+--------------+-------+\n",
            "|Window Dresser|65000.0|\n",
            "+--------------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQy49m3GF-Hj",
        "outputId": "d3de7dcd-6377-455e-d336-f3b7adacc053"
      },
      "source": [
        "# Mean salary of Dataset\n",
        "from pyspark.sql.functions import mean\n",
        "df.select(mean(\"Salary\")).show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|avg(Salary)|\n",
            "+-----------+\n",
            "|    77738.0|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmM7jteEGKh-",
        "outputId": "d86ef556-93c9-4fe1-baf2-727dff8c3a59"
      },
      "source": [
        "# Max and Min of salary column\n",
        "from pyspark.sql.functions import max, min\n",
        "df.select(max(\"Salary\"), min(\"Salary\")).show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+-----------+\n",
            "|max(Salary)|min(Salary)|\n",
            "+-----------+-----------+\n",
            "|    90000.0|    65000.0|\n",
            "+-----------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZPu52TzGxMs",
        "outputId": "88c1706d-5425-4d6d-a433-681ea432cf25"
      },
      "source": [
        "# All occupations where salaries is above 80K\n",
        "from pyspark.sql.functions import count\n",
        "df.filter(\"Salary > 80000\").select(\"occupation\").show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|          occupation|\n",
            "+--------------------+\n",
            "|              Hawker|\n",
            "|       Choreographer|\n",
            "|          Millwright|\n",
            "|   Medical Physicist|\n",
            "|           Scientist|\n",
            "|     Claims Adjustor|\n",
            "| Planning Technician|\n",
            "|       Booking Clerk|\n",
            "|      Sub-Postmaster|\n",
            "|        Shelf Filler|\n",
            "|             Chemist|\n",
            "|        Betting Shop|\n",
            "|     Hire Car Driver|\n",
            "|    Heating Engineer|\n",
            "|    Vehicle Assessor|\n",
            "|   Building Surveyor|\n",
            "|Advertising Contr...|\n",
            "|   Medical Physicist|\n",
            "|            Labourer|\n",
            "|   Technical Analyst|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "lacB-hzYHGDk",
        "outputId": "81cb079d-af2e-4c9e-fc12-5a68f978da22"
      },
      "source": [
        "# What is the average age and height for each academic degree type?\n",
        "# HINT: You will need to use `groupby` to solve this\n",
        "avg_df = df.groupBy(\"academic_degree\").avg()\n",
        "avg_df.select(\"academic_degree\", \"avg(age)\", \"avg(height_meter)\").show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-25dadc9d0246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# HINT: You will need to use `groupby` to solve this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mavg_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"academic_degree\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mavg_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"academic_degree\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg(age)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg(height_meter)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \"\"\"\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.0.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`avg(age)`' given input columns: [academic_degree, avg(Salary)];;\n'Project [academic_degree#23, 'avg(age), 'avg(height_meter)]\n+- Aggregate [academic_degree#23], [academic_degree#23, avg(Salary#358) AS avg(Salary)#469]\n   +- Project [id#16, name#17, age#18, height_meter#19, weight_kg#20, children#21, occupation#22, academic_degree#23, Salary (1k)#340, location#25, (cast(Salary (1k)#340 as double) * cast(1000 as double)) AS Salary#358]\n      +- Project [id#16, name#17, age#18, height_meter#19, weight_kg#20, children#21, occupation#22, academic_degree#23, salary#24 AS Salary (1k)#340, location#25]\n         +- Relation[id#16,name#17,age#18,height_meter#19,weight_kg#20,children#21,occupation#22,academic_degree#23,salary#24,location#25] csv\n"
          ]
        }
      ]
    }
  ]
}